{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43345e2e",
   "metadata": {},
   "source": [
    "To learn the theory behind neural networks go [here](https://cs231n.github.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd935a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21cb392",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed95b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6189c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './clothing-dataset-small/train/t-shirt'\n",
    "name = '5f0a3fa0-6a3d-4b68-b213-72766a643de7.jpg'\n",
    "fullname = f'{path}/{name}'\n",
    "load_img(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(fullname, target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f340db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90afaf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(img)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089fdaa",
   "metadata": {},
   "source": [
    "Pre-trained convolutional neural networks:\n",
    "* [Imagenet dataset](https://www.image-net.org/update-mar-11-2021.php)\n",
    "* [Pre-trained models](https://keras.io/api/applications/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924967f",
   "metadata": {},
   "source": [
    "We will use the Xception model because it is relatively small and has good accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "# Data being input into the model must be preprocessed\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "# In order to know the classes that are being predicted by the model\n",
    "from tensorflow.keras.applications.xception import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Xception(weights='imagenet', input_shape=(299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945266bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee34b8",
   "metadata": {},
   "source": [
    "The numbers that were previously between 0 and 255 are now between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195918ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a5bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f788cf14",
   "metadata": {},
   "source": [
    "Shape is 1 because there's only 1 image and there are 1000 classes, each value is the probability that the image falls into that class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4082b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_predictions(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e939d",
   "metadata": {},
   "source": [
    "The model isn't great, we don't have t-shirt as a classification, but we can build on top of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b70f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f5421",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train', \n",
    "    target_size=(150, 150), \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d4b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l clothing-dataset-small/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef8aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca6bc1",
   "metadata": {},
   "source": [
    "to get the next batch, use next, returns X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82650734",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7521df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c361a42",
   "metadata": {},
   "source": [
    "This is our target variable using one hot encoding so we have pants in the first row, a dress in the second row and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4073e26",
   "metadata": {},
   "source": [
    "Do the same thing for the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f000f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/validation', \n",
    "    target_size=(150, 150), \n",
    "    batch_size=32,\n",
    "    # images will not be shuffled, no need for validation dataset\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d95a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include_top = False means that we will exclude the dense layers\n",
    "base_model = Xception(\n",
    "    weights='imagenet', \n",
    "    include_top=False, \n",
    "    input_shape=(150, 150, 3)\n",
    ")\n",
    "\n",
    "# When we train our model we don't want to change the convolutional layers\n",
    "# The convoluational layers will remain frozen (and trained as they were in Xception)\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac987dd",
   "metadata": {},
   "source": [
    "Now we create the new dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e50ca",
   "metadata": {},
   "source": [
    "This is called the functional style of creating a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbf121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "\n",
    "# apply the base_model on the inputs to get the vector representation of the images\n",
    "# well, not quite, this gives us still a 5x5x2048 size so we need to apply pooling\n",
    "base = base_model(inputs)\n",
    "\n",
    "# this is where we are applying pooling\n",
    "# 2048 slices of 5x5 size, take the average, store the average in a vector\n",
    "vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "\n",
    "# 10 because we have 10 classes\n",
    "outputs = keras.layers.Dense(10)(vectors)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a09fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate is similar to eta in XG Boost, we will tune it later\n",
    "# choosing 0.01 for now\n",
    "learning_rate = 0.01\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682a50b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779aff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6be8ef",
   "metadata": {},
   "source": [
    "## 8.6 Adjusting the learning rate\n",
    "\n",
    "* What's the learning rate\n",
    "* Trying different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e5fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate=0.01):\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        # means that we will exclude the Dense layers from the Xception model\n",
    "        include_top=False,\n",
    "        input_shape=(150, 150, 3)\n",
    "    )\n",
    "    \n",
    "    base_model.trainable = False\n",
    "    \n",
    "    ########################################\n",
    "    \n",
    "    inputs = keras.Input(shape=(150, 150, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    outputs = keras.layers.Dense(10)(vectors)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    ########################################\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f2d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = {}\n",
    "\n",
    "# for lr in [0.0001, 0.001, 0.01, 0.1]:\n",
    "#     print(lr)\n",
    "    \n",
    "#     model = make_model(learning_rate=lr)\n",
    "#     history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "#     scores[lr] = history.history\n",
    "    \n",
    "#     print()\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lr, hist in scores.items():\n",
    "#     # plt.plot(hist['accuracy'], label=('train=%s' % lr))\n",
    "#     plt.plot(hist['val_accuracy'], label=('val=%s' %lr))\n",
    "    \n",
    "# plt.xticks(np.arange(10))\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d754c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del scores[0.1]\n",
    "# del scores[0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e9d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lr, hist in scores.items():\n",
    "#     # plt.plot(hist['accuracy'], label=('train=%s' % lr))\n",
    "#     plt.plot(hist['val_accuracy'], label=('val=%s' %lr))\n",
    "    \n",
    "# plt.xticks(np.arange(10))\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63195bb5",
   "metadata": {},
   "source": [
    "0.001 is better than 0.01 from 2 epochs and beyond except for epoch 4.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ad877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lr, hist in scores.items():\n",
    "#     plt.plot(hist['accuracy'], label=('train=%s' % lr))\n",
    "#     plt.plot(hist['val_accuracy'], label=('val=%s' %lr))\n",
    "    \n",
    "# plt.xticks(np.arange(10))\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfff895",
   "metadata": {},
   "source": [
    "We see that the 0.001 plots for val and training are closer together (blue and orange) vs the 0.01 plots (green and red) so we choose 0.001 as our learning_rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b368f",
   "metadata": {},
   "source": [
    "## 8.7 Checkpointing\n",
    "\n",
    "* Saving the best model only\n",
    "* Training a model with callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2cba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5 is a binary format for saving keras models\n",
    "model.save_weights('model_v1.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6bae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2906a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template for saving files in keras\n",
    "'xception_v1_{epoch:02d}_{val_accuracy:.3f}.h5'.format(epoch=3, val_accuracy=0.84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da0a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'xception_v1_{epoch:02d}_{val_accuracy:.3f}.h5',\n",
    "    # save the model only if it's an improvement over the best one we've seen so far\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    # maximize accuracy\n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4603370",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model = make_model(learning_rate=learning_rate)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6305ad73",
   "metadata": {},
   "source": [
    "## 8.8 Adding more layers\n",
    "\n",
    "\n",
    "* Adding one inner dense layer\n",
    "* Experimenting with different sizes of inner layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b133b863",
   "metadata": {},
   "source": [
    "Let's plot the best model we have so far so that we have it for comparison purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dee3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the best model from the checkpointing exercise:\n",
    "from keras.models import load_model\n",
    "model = load_model('xception_v1_10_0.839.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ca4b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e4b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77694cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate=0.01, size_inner=100):\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(150, 150, 3)\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    inputs = keras.Input(shape=(150, 150, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    \n",
    "    # adding a new inner layer with activation of relu\n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    \n",
    "    outputs = keras.layers.Dense(10)(inner)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac307d7",
   "metadata": {},
   "source": [
    "Training the model with various values for the `size_inner` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3669d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for size in [10, 100, 1000]:\n",
    "    print(size)\n",
    "\n",
    "    model = make_model(learning_rate=learning_rate, size_inner=size)\n",
    "    history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "    scores[size] = history.history\n",
    "\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807acbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for size, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % size))\n",
    "\n",
    "plt.xticks(np.arange(10))\n",
    "plt.yticks([0.78, 0.80, 0.82, 0.825, 0.83])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c31cb41",
   "metadata": {},
   "source": [
    "This extra layer doesn't really improve the model. We'll use `size_inner=100`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f754f",
   "metadata": {},
   "source": [
    "## 8.9 Regularization and dropout\n",
    "\n",
    "* Regularizing by freezing a part of the network\n",
    "* Adding dropout to our model\n",
    "* Experimenting with different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9525ff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate=0.01, size_inner=100, droprate=0.5):\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(150, 150, 3)\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    inputs = keras.Input(shape=(150, 150, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    \n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    # here we are dropping out part of the data\n",
    "    drop = keras.layers.Dropout(droprate)(inner)\n",
    "    \n",
    "    outputs = keras.layers.Dense(10)(drop)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08501f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "size = 100\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for droprate in [0.0, 0.2, 0.5, 0.8]:\n",
    "    print(droprate)\n",
    "\n",
    "    model = make_model(\n",
    "        learning_rate=learning_rate,\n",
    "        size_inner=size,\n",
    "        droprate=droprate\n",
    "    )\n",
    "\n",
    "    history = model.fit(train_ds, epochs=30, validation_data=val_ds)\n",
    "    scores[droprate] = history.history\n",
    "\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for droprate, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % droprate))\n",
    "\n",
    "plt.ylim(0.78, 0.86)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e71d0d",
   "metadata": {},
   "source": [
    "Removing 0 and 0.8 because they didn't perform very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3618b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = scores[0.2]\n",
    "plt.plot(hist['val_accuracy'], label=0.2)\n",
    "\n",
    "hist = scores[0.5]\n",
    "plt.plot(hist['val_accuracy'], label=0.5)\n",
    "\n",
    "plt.legend()\n",
    "#plt.plot(hist['accuracy'], label=('val=%s' % droprate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468a7884",
   "metadata": {},
   "source": [
    "We do see improvement in the accuracy by adding droprate.  The actual value to use is kind of a toss up between 0.2 and 0.5.  We'll choose a droprate of 0.2 moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f058d",
   "metadata": {},
   "source": [
    "## 8.10 Data augmentation\n",
    "\n",
    "* Different data augmentations\n",
    "* Training a model with augmentations\n",
    "* How to select data augmentations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b22d36a",
   "metadata": {},
   "source": [
    "We want to try each augmentation one by one to see which one adds value and which one we can skip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a17409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# static for the entire data augmentation exercise:\n",
    "learning_rate = 0.001\n",
    "size = 100\n",
    "droprate = 0.2\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/validation',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(learning_rate, size, droprate):\n",
    "    model = make_model(\n",
    "    learning_rate=learning_rate,\n",
    "    size_inner=size,\n",
    "    droprate=droprate\n",
    "    )\n",
    "\n",
    "    # 20 epochs to make this process a bit faster\n",
    "    history = model.fit(train_ds, epochs=20, validation_data=val_ds)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5b591",
   "metadata": {},
   "source": [
    "rotation_range=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "history = train_model(learning_rate, size, droprate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['val_accuracy'], label='val')\n",
    "plt.plot(hist['accuracy'], label='train')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d4309",
   "metadata": {},
   "source": [
    "Verdict: we exclude rotation because it actually made the model worse (oscillating around 0.8 whereas the original model was closer to 0.83)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2c82d3",
   "metadata": {},
   "source": [
    "width_shift_range=10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60aaac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    width_shift_range=10.0\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "history = train_model(learning_rate, size, droprate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60604171",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['val_accuracy'], label='val')\n",
    "# plt.plot(hist['accuracy'], label='train')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d94d15f",
   "metadata": {},
   "source": [
    "Verdict: we exclude width_shift_range because it actually made the model worse (oscillating around 0.81 whereas the original model was closer to 0.83)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cd8f74",
   "metadata": {},
   "source": [
    "height_shift_range=10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    height_shift_range=10.0\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "history = train_model(learning_rate, size, droprate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da37019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['val_accuracy'], label='val')\n",
    "# plt.plot(hist['accuracy'], label='train')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187b18d4",
   "metadata": {},
   "source": [
    "Verdict: we exclude height_shift_range because it actually made the model worse (oscillating around 0.81 whereas the original model was closer to 0.83)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea17aa",
   "metadata": {},
   "source": [
    "shear_range=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a7850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    shear_range=10\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "history = train_model(learning_rate, size, droprate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91266276",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['val_accuracy'], label='val')\n",
    "plt.plot(hist['accuracy'], label='train')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0f32b8",
   "metadata": {},
   "source": [
    "Verdict: we see that the accuracy difference between training and validation is smaller than when we didn't include this augmentation option.  Even though there isn't a significant improvement in performance of this model (oscillating around 0.82, similar to the original model of 0.83), we should include this augmentation so as to mitigate overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471eaa75",
   "metadata": {},
   "source": [
    "zoom_range=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdf9c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "history = train_model(learning_rate, size, droprate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0315b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['val_accuracy'], label='val')\n",
    "# plt.plot(hist['accuracy'], label='train')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cab7fd5",
   "metadata": {},
   "source": [
    "Verdict: we include zoom_range as well, for similar reasons as we included shear_range)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59128d2",
   "metadata": {},
   "source": [
    "horizontal_flip=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f0912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "history = train_model(learning_rate, size, droprate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db95bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['val_accuracy'], label='val')\n",
    "# plt.plot(hist['accuracy'], label='train')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0046d3bb",
   "metadata": {},
   "source": [
    "Verdict: we exclude horizontal_flip because it actually made the model worse (oscillating around 0.81 whereas the original model was closer to 0.83)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e109d33",
   "metadata": {},
   "source": [
    "vertical_flip=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b8100",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "history = train_model(learning_rate, size, droprate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1776e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['val_accuracy'], label='val')\n",
    "# plt.plot(hist['accuracy'], label='train')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47e8246",
   "metadata": {},
   "source": [
    "Verdict: we exclude vertical_flip because it actually made the model worse (oscillating around 0.80 whereas the original model was closer to 0.83)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21d9e6c",
   "metadata": {},
   "source": [
    "## 8.11 Training a larger model\n",
    "\n",
    "* Train a 299x299 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754ac36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_size=150, learning_rate=0.01, size_inner=100,\n",
    "               droprate=0.5):\n",
    "\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(input_size, input_size, 3)\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    \n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    drop = keras.layers.Dropout(droprate)(inner)\n",
    "    \n",
    "    outputs = keras.layers.Dense(10)(drop)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c653aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be62c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    shear_range=10,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(input_size, input_size),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/validation',\n",
    "    target_size=(input_size, input_size),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'xception_v4_1_{epoch:02d}_{val_accuracy:.3f}.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa03dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "size = 100\n",
    "droprate = 0.2\n",
    "\n",
    "model = make_model(\n",
    "    input_size=input_size,\n",
    "    learning_rate=learning_rate,\n",
    "    size_inner=size,\n",
    "    droprate=droprate\n",
    ")\n",
    "\n",
    "history = model.fit(train_ds, epochs=50, validation_data=val_ds,\n",
    "                   callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a57583b",
   "metadata": {},
   "source": [
    "Stopping at 30 because the validation accuracy is trending downward..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425e379",
   "metadata": {},
   "source": [
    "## 8.12 Using the model\n",
    "\n",
    "* Loading the model\n",
    "* Evaluating the model\n",
    "* Getting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace8b82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 06:05:54.396427: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7543295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "from tensorflow.keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cc52a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 372 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_ds = test_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/test',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76ec6374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 06:06:11.652983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-15 06:06:11.663251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-15 06:06:11.666519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-15 06:06:11.670003: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-15 06:06:11.670380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-15 06:06:11.673695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-15 06:06:11.676826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-15 06:06:12.377329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-15 06:06:12.378777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-15 06:06:12.379896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-15 06:06:12.380972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13623 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('xception_v4_1_19_0.894.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d5eeced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 06:06:20.876500: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2024-03-15 06:06:21.523769: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-15 06:06:21.524446: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-15 06:06:21.524481: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2024-03-15 06:06:21.525135: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-03-15 06:06:21.525211: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 7s 274ms/step - loss: 0.2676 - accuracy: 0.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2675786018371582, 0.9166666865348816]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ed88b",
   "metadata": {},
   "source": [
    "We had 0.894 on the validation dataset and 0.917 on the test dataset which is even higher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f497dcef",
   "metadata": {},
   "source": [
    "Use the final model to predict the type of clothes for a certain image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e3dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'clothing-dataset-small/test/pants/c8d21106-bbdb-4e8d-83e4-bf3d14e54c16.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8ff4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(path, target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "124dba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38057a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 299, 299, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(img)\n",
    "X = np.array([x])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b04b88ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 299, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59e2835d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[140, 136, 125],\n",
       "         [141, 137, 126],\n",
       "         [143, 139, 128],\n",
       "         ...,\n",
       "         [134, 130, 118],\n",
       "         [135, 131, 119],\n",
       "         [122, 118, 106]],\n",
       "\n",
       "        [[143, 139, 128],\n",
       "         [145, 141, 130],\n",
       "         [146, 142, 131],\n",
       "         ...,\n",
       "         [134, 130, 118],\n",
       "         [135, 131, 119],\n",
       "         [127, 123, 111]],\n",
       "\n",
       "        [[145, 141, 130],\n",
       "         [147, 143, 132],\n",
       "         [148, 144, 133],\n",
       "         ...,\n",
       "         [133, 129, 117],\n",
       "         [135, 131, 119],\n",
       "         [131, 127, 115]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[153, 151, 130],\n",
       "         [151, 148, 129],\n",
       "         [150, 147, 128],\n",
       "         ...,\n",
       "         [143, 131, 115],\n",
       "         [137, 125, 109],\n",
       "         [118, 106,  90]],\n",
       "\n",
       "        [[143, 141, 120],\n",
       "         [144, 141, 122],\n",
       "         [146, 143, 124],\n",
       "         ...,\n",
       "         [114, 102,  86],\n",
       "         [106,  94,  78],\n",
       "         [103,  91,  75]],\n",
       "\n",
       "        [[133, 131, 110],\n",
       "         [136, 133, 114],\n",
       "         [138, 135, 116],\n",
       "         ...,\n",
       "         [ 98,  86,  70],\n",
       "         [ 88,  76,  60],\n",
       "         [ 83,  71,  55]]]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6260c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5951e505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 878ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9758cdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.7067122, -4.047572 , -2.8784268, -3.1026635,  8.912214 ,\n",
       "        -1.2892189, -4.443411 ,  3.4327233, -4.9830856, -4.866729 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eee6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96abe6f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -4.7067122,\n",
       " 'hat': -4.047572,\n",
       " 'longsleeve': -2.8784268,\n",
       " 'outwear': -3.1026635,\n",
       " 'pants': 8.912214,\n",
       " 'shirt': -1.2892189,\n",
       " 'shoes': -4.443411,\n",
       " 'shorts': 3.4327233,\n",
       " 'skirt': -4.9830856,\n",
       " 't-shirt': -4.866729}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_pred_dict = dict(zip(classes, pred[0]))\n",
    "item_pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1510f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_type(item_dict):\n",
    "    for clothing_type in item_dict:\n",
    "        max_val = max(item_dict.values())\n",
    "        if item_dict[clothing_type] == max_val:\n",
    "            return clothing_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfe632e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pants'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type(item_pred_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35881b2e",
   "metadata": {},
   "source": [
    "## 8.13 Summary\n",
    "\n",
    "* We can use pre-trained models for general image classification\n",
    "* Convolutional layers let us turn an image into a vector\n",
    "* Dense layers use the vector to make the predictions\n",
    "* Instead of training a model from scratch, we can use transfer learning and re-use already trained convolutional layers\n",
    "* First, train a small model (150x150) before training a big one (299x299)\n",
    "* Learning rate - how fast the model trians. Fast learners aren't always best ones\n",
    "* We can save the best model using callbacks and checkpointing\n",
    "* To avoid overfitting, use dropout and augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50ce628",
   "metadata": {},
   "source": [
    "## 8.14 Explore more\n",
    "\n",
    "* Add more data, e.g. Zalando, etc (ADD LINKS)\n",
    "* Albumentations - another way of generating augmentations\n",
    "* Use PyTorch or MXNet instead of TensorFlow/Keras\n",
    "* In addition to Xception, there are others architectures - try them \n",
    "\n",
    "Other projects:\n",
    "\n",
    "* cats vs dogs\n",
    "* Hotdog vs not hotdog\n",
    "* Category of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c83f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
